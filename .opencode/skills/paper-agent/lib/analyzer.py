#!/usr/bin/env python3
"""
Lib: PDF Analyzer
ä½¿ç”¨OpenRouter APIæ·±åº¦åˆ†æPDFè®ºæ–‡
"""

import os
import json
import base64
import time
import logging
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('paper_agent_analysis.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# è®ºæ–‡åˆ†æçš„prompt
ANALYSIS_PROMPT = """è¯·ä½œä¸ºèµ„æ·±ç ”ç©¶å‘˜åˆ†æè¿™ç¯‡å­¦æœ¯è®ºæ–‡ï¼Œä»PDFä¸­æå–å…³é”®ä¿¡æ¯ï¼ŒæŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºMarkdownæ ¼å¼æŠ¥å‘Šï¼š

## åŸºæœ¬ä¿¡æ¯
- **æ ‡é¢˜**: ï¼ˆè®ºæ–‡å®Œæ•´æ ‡é¢˜ï¼‰
- **ä½œè€…**: ï¼ˆä½œè€…åˆ—è¡¨ï¼‰
- **ä¼šè®®/æœŸåˆŠ**: ï¼ˆå‘è¡¨åœºæ‰€ï¼‰
- **å¹´ä»½**: ï¼ˆå‘è¡¨å¹´ä»½ï¼‰

## ç ”ç©¶èƒŒæ™¯
- **ç ”ç©¶é—®é¢˜**: ï¼ˆè®ºæ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼‰
- **ç°æœ‰é—®é¢˜**: ï¼ˆå½“å‰æ–¹æ³•çš„å±€é™æ€§ï¼‰
- **æ ¸å¿ƒæŒ‘æˆ˜**: ï¼ˆæŠ€æœ¯éš¾ç‚¹ï¼‰

## æ ¸å¿ƒæ–¹æ³•
- **ä¸»è¦æŠ€æœ¯**: ï¼ˆ1-2å¥è¯æ¦‚æ‹¬ä¸»è¦æŠ€æœ¯ï¼‰
- **å…³é”®æŠ€æœ¯ç»„ä»¶**: ï¼ˆ2-4ä¸ªæŠ€æœ¯è¦ç‚¹ï¼‰
- **åˆ›æ–°ç‚¹**: ï¼ˆä¸ç°æœ‰æ–¹æ³•çš„åŒºåˆ«ï¼‰
- **æ¶æ„å›¾**: ï¼ˆå¦‚æœ‰ï¼Œæè¿°æ•´ä½“æµç¨‹ï¼‰

## å®éªŒç»“æœ
- **æ•°æ®é›†**: ï¼ˆä½¿ç”¨çš„æ‰€æœ‰æ•°æ®é›†åç§°ï¼‰
- **è¯„ä»·æŒ‡æ ‡**: ï¼ˆä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼‰
- **ä¸»è¦ç»“æœ**: ï¼ˆå…³é”®æ€§èƒ½æ•°å­—ï¼‰
- **ä¸SOTAå¯¹æ¯”**: ï¼ˆç›¸å¯¹æå‡å¹…åº¦ï¼‰

## ä¸»è¦è´¡çŒ®
- **ç†è®ºè´¡çŒ®**: ï¼ˆæ–°çš„ç†è®º/ç®—æ³•ï¼‰
- **å®è·µè´¡çŒ®**: ï¼ˆå®é™…åº”ç”¨ä»·å€¼ï¼‰
- **å¼€æºè´¡çŒ®**: ï¼ˆä»£ç /æ•°æ®æ˜¯å¦å¼€æºï¼‰

## å¼€æºä¿¡æ¯
- **ä»£ç å¼€æº**: ï¼ˆæ˜¯/å¦/æœªæåŠï¼‰
- **ä»£ç é“¾æ¥**: ï¼ˆGitHubæˆ–å…¶ä»–ä»“åº“URLï¼‰
- **é¢„è®­ç»ƒæ¨¡å‹**: ï¼ˆæ˜¯å¦æä¾›ï¼‰
- **æ•°æ®é›†**: ï¼ˆæ˜¯å¦å…¬å¼€å¯ç”¨ï¼‰

è¯·åŸºäºPDFå†…å®¹å‡†ç¡®æå–ä¿¡æ¯ï¼Œå¦‚æœæŸäº›ä¿¡æ¯æœªåœ¨è®ºæ–‡ä¸­æ˜ç¡®æåŠï¼Œè¯·æ ‡æ³¨"æœªæåŠ"ã€‚ä¸è¦æ·»åŠ é¢å¤–çš„è¯„ä»·æˆ–ä¸ªäººè§‚ç‚¹ã€‚"""


def encode_pdf_to_base64(pdf_path: str) -> str:
    """å°†PDFæ–‡ä»¶ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
    with open(pdf_path, "rb") as pdf_file:
        return base64.b64encode(pdf_file.read()).decode('utf-8')


def analyze_pdf(
    pdf_path: str,
    api_key: str,
    model: str = "stepfun/step-3.5-flash:free",
    max_retries: int = 3,
    timeout: int = 120
) -> Optional[str]:
    """åˆ†æå•ç¯‡PDFè®ºæ–‡"""
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    try:
        # ç¼–ç PDF
        base64_pdf = encode_pdf_to_base64(pdf_path)
        data_url = f"data:application/pdf;base64,{base64_pdf}"
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": ANALYSIS_PROMPT},
                    {
                        "type": "file",
                        "file": {
                            "filename": os.path.basename(pdf_path),
                            "file_data": data_url
                        }
                    },
                ]
            }
        ]
        
        # æ’ä»¶é…ç½®
        plugins = [{"id": "file-parser", "pdf": {"engine": "pdf-text"}}]
        
        payload = {
            "model": model,
            "messages": messages,
            "plugins": plugins,
            "stream": False
        }
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    url, headers=headers, json=payload, timeout=timeout
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if 'choices' in result and len(result['choices']) > 0:
                        return result['choices'][0]['message']['content']
                    else:
                        logger.warning(f"APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}")
                else:
                    logger.warning(f"APIè¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): HTTP {response.status_code}")
                    
            except requests.exceptions.RequestException as e:
                logger.warning(f"è¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            
            # é‡è¯•å‰ç­‰å¾…
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        
        logger.error(f"åˆ†æå¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {pdf_path}")
        return None
        
    except Exception as e:
        logger.error(f"å¤„ç†PDFæ—¶å‘ç”Ÿé”™è¯¯ {pdf_path}: {e}")
        return None


def process_single_pdf(
    pdf_path: Path,
    output_dir: Path,
    api_key: str,
    model: str,
    overwrite: bool = False
) -> Tuple[bool, str]:
    """å¤„ç†å•ç¯‡PDFå¹¶ä¿å­˜ç»“æœ"""
    try:
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        output_file = output_dir / f"{pdf_path.stem}_analysis.md"
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if not overwrite and output_file.exists():
            return True, f"è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {pdf_path.name}"
        
        # åˆ†æPDF
        analysis = analyze_pdf(str(pdf_path), api_key, model)
        
        if analysis is None:
            return False, f"åˆ†æå¤±è´¥: {pdf_path.name}"
        
        # ä¿å­˜ç»“æœ
        output_dir.mkdir(parents=True, exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(analysis)
        
        return True, f"å®Œæˆ: {pdf_path.name}"
        
    except Exception as e:
        logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {pdf_path}: {e}")
        return False, f"å¤„ç†å¤±è´¥: {pdf_path.name} - {e}"


def find_pdf_files(input_dir: Path) -> List[Path]:
    """æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶"""
    return sorted(input_dir.rglob("*.pdf"))


def analyze_papers(
    input_dir: Path,
    output_dir: Path,
    api_key: str,
    model: str = "stepfun/step-3.5-flash:free",
    max_workers: int = 4,
    overwrite: bool = False
) -> Dict:
    """
    æ‰¹é‡åˆ†æPDFæ–‡ä»¶
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ é˜¶æ®µ4: PDFæ·±åº¦åˆ†æ")
    print(f"{'='*60}")
    print(f"è¾“å…¥ç›®å½•: {input_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"å¹¶è¡Œæ•°: {max_workers}")
    print(f"æ¨¡å‹: {model}")
    print(f"{'='*60}\n")
    
    # éªŒè¯è¾“å…¥ç›®å½•
    if not input_dir.exists():
        logger.error(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return {'success': 0, 'failed': 0, 'total': 0}
    
    # æŸ¥æ‰¾æ‰€æœ‰PDF
    pdf_files = find_pdf_files(input_dir)
    
    if not pdf_files:
        logger.warning(f"åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°PDFæ–‡ä»¶")
        return {'success': 0, 'failed': 0, 'total': 0}
    
    logger.info(f"æ‰¾åˆ° {len(pdf_files)} ç¯‡PDFè®ºæ–‡å¾…åˆ†æ")
    
    # ç»Ÿè®¡
    success_count = 0
    fail_count = 0
    
    # ä½¿ç”¨ThreadPoolExecutorå¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_pdf = {
            executor.submit(
                process_single_pdf, pdf_path, output_dir, api_key, model, overwrite
            ): pdf_path for pdf_path in pdf_files
        }
        
        # æ˜¾ç¤ºè¿›åº¦
        total = len(pdf_files)
        for i, future in enumerate(future_to_pdf, 1):
            pdf_path = future_to_pdf[future]
            try:
                success, message = future.result()
                if success:
                    success_count += 1
                    print(f"[{i}/{total}] âœ… {message}")
                else:
                    fail_count += 1
                    print(f"[{i}/{total}] âŒ {message}")
                    
            except Exception as e:
                fail_count += 1
                print(f"[{i}/{total}] âŒ ä»»åŠ¡å¼‚å¸¸ {pdf_path.name}: {e}")
    
    # è¾“å‡ºç»Ÿè®¡
    print(f"\n{'='*60}")
    print(f"âœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"   æ€»è®ºæ–‡æ•°: {len(pdf_files)}")
    print(f"   æˆåŠŸ: {success_count}")
    print(f"   å¤±è´¥: {fail_count}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"{'='*60}\n")
    
    if fail_count > 0:
        print(f"æŸ¥çœ‹é”™è¯¯æ—¥å¿—: paper_agent_analysis.log")
    
    return {
        'total': len(pdf_files),
        'success': success_count,
        'failed': fail_count
    }
